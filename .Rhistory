lp
}
nsim <- 18
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
lpR
knitr::opts_chunk$set(echo = FALSE)
# log-posterior in Stan
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit, Pars[[ii]])
log_prob(object = hnm_fit, upars = upars, adjust_transform = FALSE)
})
lpR-lpStan
detach("package:invgamma", unload = TRUE)
#' Log-Posterior Function
#'
#' @description  `logpost` returns the log-posterior of the hierarchical model given the parameter values and observations
#'
#' @param lambda A real number, the hyperparameter
#' @param mu_raw A vector of reals at the same length of y
#' @param tau_sq A positive number, the hyperparameter
#' @param sigma_sq A positive number
#' @param y A vector of reals
#' @return The log-posterior values
#' @details The hyper-prior are given by tau_sq ~ InverseGamma(1,1) and lambda ~ Uniform, where the constant uniform probability are eliminated in calculating the log-posterior.
#' The prior are given by mu_raw ~ N(0,1 ) and sigma_sq InverseGamma(1,1), while the non-centered parameterization are implemented here.
#' The likelihood are given by the Normal(mu, sigma_sq)
#' @import invgamma
logpost <- function(lambda, mu_raw, tau_sq, sigma_sq, y) {
lp <- dinvgamma(tau_sq, shape = 1, scale = 1, log = TRUE)
# Prior:
lp <- lp + dinvgamma(sigma_sq, shape = 1, scale = 1, log = TRUE)
lp <- lp + sum(dnorm(mu_raw, log = TRUE))
# likelihood:
mu <- lambda + sqrt(tau_sq) * mu_raw
lp <- lp + sum(dnorm(y, mean = mu, sd = sqrt(sigma_sq), log = TRUE))
# output:
lp
}
# Simulate parameter values
# fixed lambda and tau_sq to get constant difference between
# R and stan
nsim <- 18
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
# Simulate parameter values
nsim <- 10
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
#' Log-Posterior Function
#'
#' @description  `logpost` returns the log-posterior of the hierarchical model given the parameter values and observations
#'
#' @param lambda A real number, the hyperparameter
#' @param mu_raw A vector of reals at the same length of y
#' @param tau_sq A positive number, the hyperparameter
#' @param sigma_sq A positive number
#' @param y A vector of reals
#' @return The log-posterior values
#' @details The hyper-prior are given by tau_sq ~ InverseGamma(1,1) and lambda ~ Uniform, where the constant uniform probability are eliminated in calculating the log-posterior.
#' The prior are given by mu_raw ~ N(0,1 ) and sigma_sq InverseGamma(1,1), while the non-centered parameterization are implemented here.
#' The likelihood are given by the Normal(mu, sigma_sq)
#' @import invgamma
#' @export
logpost <- function(lambda, mu_raw, tau_sq, sigma_sq, y) {
require(invgamma)
# Hyper-prior:
lp <- dinvgamma(tau_sq, shape = 1, scale = 1, log = TRUE)
# Prior:
lp <- lp + dinvgamma(sigma_sq, shape = 1, scale = 1, log = TRUE)
lp <- lp + sum(dnorm(mu_raw, log = TRUE))
# likelihood:
mu <- lambda + sqrt(tau_sq) * mu_raw
lp <- lp + sum(dnorm(y, mean = mu, sd = sqrt(sigma_sq), log = TRUE))
# output:
lp
}
# Simulate parameter values
nsim <- 10
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
# log-posterior in Stan
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit, Pars[[ii]])
log_prob(object = hnm_fit, upars = upars, adjust_transform = FALSE)
})
lpR-lpStan # return exactly same constant
-(2*N)*log(sqrt(2*pi))
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Simulate parameter values
nsim <- 10
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
# log-posterior in Stan
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit, Pars[[ii]])
log_prob(object = hnm_fit, upars = upars, adjust_transform = FALSE)
})
lpR-lpStan # return exactly same constant
-(2*N)*log(sqrt(2*pi))
library(bookdown)
knitr::opts_chunk$set(eval = FALSE, message = FALSE)
theta <- c("lambda","tau_sq","sigma_sq", "lp__")
theta.names <- c(paste0('lambda'),  paste0('tau^2'),
paste0('sigma^2'),paste0('log-post'))
theta.names <- parse(text = theta.names)
theta.names
stan_dens(hnm_fit, pars = theta, separate_chains = TRUE)
hist(hnm_post$lambda, breaks = 100, probability = TRUE,
main = 'mean', xlab = expression(lambda))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'red')
hist(hnm_post$lambda, breaks = 100, probability = TRUE,
main = 'mean', xlab = expression(lambda))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'green')
hist(hnm_post$lambda, breaks = 100, probability = TRUE,
main = 'mean', xlab = expression(lambda))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange')
hist(hnm_post$lambda, breaks = 100, probability = TRUE, col = 'white',
main = 'mean', xlab = expression(lambda))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange')
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'mean', xlab = expression(lambda))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange')
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'mean', xlab = expression(lambda)), ylim=c(0,1)
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'mean', xlab = expression(lambda)), ylim=c(0,1))
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,1))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange')
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange')
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_lam, lty = 2, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 1, lwd = 2, col = 'orange')
legend("right", col = c("red", "orange"), c("True Mean","Mean of posterior"), lty = c(2,1), cex = 1, bty='n')# add legends
hist(hnm_post$lambda, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_lam, lty = 1, lwd = 2, col = 'red')
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange')
legend("right", col = c("red", "orange"), c("True Mean","Mean of posterior"),
lty = c(1,2), cex = 1, bty='n')# add legends
stan_trace(hnm_fit, pars = theta)
theta <- c("lambda","tau_sq","sigma_sq")
theta.names <- c(paste0('lambda'),  paste0('tau^2'),
paste0('sigma^2'))
theta.names <- parse(text = theta.names)
stan_trace(hnm_fit, pars = theta)
stan_trace(hnm_fit, pars = theta)
stan_dens(hnm_fit, pars = theta)
stan_dens(hnm_fit, pars = theta, separate_chains = TRUE)
# plot the histogram of the mcmc samples
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lambda_seq <- seq(min(lambda_post), max(lambda_post), len = 200)
lambda_pdf <- dnorm(lambda_seq, mean = sum(true_mu^2), sd = sqrt(true_tau2/n))
# plot the histogram of the mcmc samples
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lambda_seq <- seq(min(lambda_post), max(lambda_post), len = 200)
lambda_pdf <- dnorm(lambda_seq, mean = sum(true_mu^2), sd = sqrt(true_tau2/N))
lines(lambda_seq, lambda_pdf, col = "red")
abline(v = true_lam, lty = 1, lwd = 2, col = 'red') # True population mean
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange') # Posterior mean
legend("right", col = c("red", "orange"), c("True Mean","Mean of posterior"),
lty = c(1,2), cex = 1, bty='n')# add legends
lambda_seq
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lambda_seq <- seq(min(lambda_post), max(lambda_post), len = 200)
lambda_pdf <- dnorm(lambda_seq, mean = sum(true_mu^2), sd = sqrt(true_tau2/N))
lines(lambda_seq, lambda_pdf, col = "red")
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lambda_seq <- seq(min(lambda_post), max(lambda_post), len = 200)
lambda_pdf <- dnorm(lambda_seq, mean = mean(true_mu^2), sd = sqrt(true_tau2/N))
lines(lambda_seq, lambda_pdf, col = "red")
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lambda_seq <- seq(min(lambda_post), max(lambda_post), len = 200)
lambda_pdf <- pnorm(lambda_seq, mean = mean(true_mu^2), sd = sqrt(true_tau2/N))
lines(lambda_seq, lambda_pdf, col = "red")
summary(lambda_pdf)
lambda_pdf <- dnorm(lambda_seq, mean = mean(true_mu^2), sd = sqrt(true_tau2/N))
summary(lambda_pdf)
true_mu
true_mu^2
mean(true_mu^2)
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
install.packages("bayesplot")
# plot the histogram of the mcmc samples
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_lam, lty = 1, lwd = 2, col = 'red') # True population mean
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange') # Posterior mean
legend("right", col = c("red", "orange"), c("True Mean","Mean of posterior"),
lty = c(1,2), cex = 1, bty='n')# add legends
require(bayesplot)
pp_check(hnm_fit)
set.seed(42) # for reproducibility
N <- 20 # number of clusters
true_lam <- 3 # true population mean
true_tau2 <- 1.5 # true between-cluster variance
true_sig2 <- 1.2 # true within-cluster variance
true_mu <-true_lam + sqrt(true_tau2)*rnorm(N) # true cluster means
y <- true_mu + sqrt(true_sig2)*rnorm(N) # observed data input for models
knitr::opts_chunk$set(eval = FALSE, message = FALSE)
require(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = 1)
# Compile the model
hnm_mod <- stan_model(file = "HierNorm.stan")
# Construct log-posterior for this data in Stan
#  1. format data:
#   list with elements named exactly as "data" block in Stan
hnm_data <- list(N = N, y = y)
#  2. associate data with model:
#   to do this, MCMC sample for one iteration.
hnm_fit_init <- sampling(hnm_mod, data = hnm_data, iter = 1,
verbose = TRUE, chains = 1)
#' Log-Posterior Function
#'
#' @description  `logpost` returns the log-posterior of the hierarchical model given the parameter values and observations
#'
#' @param lambda A real number, the hyperparameter
#' @param mu_raw A vector of reals at the same length of y
#' @param tau_sq A positive number, the hyperparameter
#' @param sigma_sq A positive number
#' @param y A vector of reals
#' @return The log-posterior values
#' @details The hyper-prior are given by tau_sq ~ InverseGamma(1,1) and lambda ~ Uniform, where the constant uniform probability are eliminated in calculating the log-posterior.
#' The prior are given by mu_raw ~ N(0,1 ) and sigma_sq InverseGamma(1,1), while the non-centered parameterization are implemented here.
#' The likelihood are given by the Normal(mu, sigma_sq)
#' @import invgamma
#' @export
logpost <- function(lambda, mu_raw, tau_sq, sigma_sq, y) {
require(invgamma)
# Hyper-prior:
lp <- dinvgamma(tau_sq, shape = 1, scale = 1, log = TRUE)
# Prior:
lp <- lp + dinvgamma(sigma_sq, shape = 1, scale = 1, log = TRUE)
lp <- lp + sum(dnorm(mu_raw, log = TRUE))
# likelihood:
mu <- lambda + sqrt(tau_sq) * mu_raw
lp <- lp + sum(dnorm(y, mean = mu, sd = sqrt(sigma_sq), log = TRUE))
# output:
lp
}
# Simulate parameter values:
nsim <- 10 # number of simulations to conduct
# randomly generated parameter values to check the correctness
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R:
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
# log-posterior calculation in Stan:
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit, Pars[[ii]])
log_prob(object = hnm_fit_init, upars = upars, adjust_transform = FALSE)
})
# log-posterior calculation in Stan:
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit_init, Pars[[ii]])
log_prob(object = hnm_fit_init, upars = upars, adjust_transform = FALSE)
})
lpR-lpStan # return exactly same constant
-(2*N)*log(sqrt(2*pi)) # Theoretical difference
# sampling
nsamples <- 1e5
theta <- c("lambda","tau_sq","sigma_sq", "lp__")
stan_time <- system.time(
hnm_fit <- sampling(hnm_mod, data = hnm_data, iter = nsamples,
control = list(adapt_delta = 0.99, max_treedepth = 15)))
saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time, hnm_data = hnm_data, hnm_fit_init=hnm_fit_init, hnm_mod = hnm_mod), file = "hnm_post.rds")
# extract MCMC samples
hnm_post <- extract(hnm_fit)
theta <- c("lambda","tau_sq","sigma_sq")
theta.names <- c(paste0('lambda'),  paste0('tau^2'),
paste0('sigma^2'))
theta.names <- parse(text = theta.names)
par(mfrow = c(2,3))
stan_trace(hnm_fit, pars = theta)
stan_dens(hnm_fit, pars = theta, separate_chains = TRUE)
# plot the histogram of the MCMC samples of population mean
lambda_post = hnm_post$lambda
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Posterior of Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_lam, lty = 1, lwd = 2, col = 'red') # True population mean
abline(v = mean(hnm_post$lambda), lty = 2, lwd = 2, col = 'orange') # Posterior mean
legend("right", col = c("red", "orange"), c("True Mean","Mean of Posterior"),
lty = c(1,2), cex = 1, bty='n')# add legends
saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time, hnm_mod = hnm_mod), file = "hnm_post.rds")
saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time), file = "hnm_post.rds")
saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time, hnm_mod = hnm_mod), file = "hnm_post.rds")
saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time, hnm_data = hnm_data,
hnm_fit_init=hnm_fit_init, hnm_mod = hnm_mod), file = "hnm_post.rds")
hnm_mcmc <- readRDS('hnm_post.rds')
hnm_fit_init <- hnm_mcmc$hnm_fit_init # initailized mdoel fit to check the log-posterior against R
hnm_fit <- hnm_mcmc$hnm_fit # MCMC samples
stan_time <- hnm_mcmc$stan_time
hnm_mod <- hnm_mcmc$hnm_mod
hnm_post <- extract(hnm_fit)
rm(hnm_mcmc)
# log-posterior calculation in Stan:
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit_init, Pars[[ii]])
log_prob(object = hnm_fit_init, upars = upars, adjust_transform = FALSE)
})
#  2. associate data with model:
#   to do this, MCMC sample for one iteration.
hnm_fit_init <- sampling(hnm_mod, data = hnm_data, iter = 1,
verbose = TRUE, chains = 1)
# Simulate parameter values:
nsim <- 10 # number of simulations to conduct
# randomly generated parameter values to check the correctness
Pars <- replicate(n = nsim, expr = {
list(lambda = rexp(1), mu_raw = rnorm(N),
tau_sq = rexp(1)*5, sigma_sq = rexp(1)*2)
}, simplify = FALSE)
# log-posterior calculation in R:
lpR <- sapply(1:nsim, function(ii) {
lambda <- Pars[[ii]]$lambda
mu_raw <- Pars[[ii]]$mu_raw
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda = lambda, mu_raw = mu_raw, tau_sq = tau_sq,
sigma_sq = sigma_sq, y = hnm_data$y)
})
# log-posterior calculation in Stan:
lpStan <- sapply(1:nsim, function(ii) {
upars <- unconstrain_pars(object = hnm_fit_init, Pars[[ii]])
log_prob(object = hnm_fit_init, upars = upars, adjust_transform = FALSE)
})
lpR-lpStan # return exactly same constant
-(2*N)*log(sqrt(2*pi)) # Theoretical difference
require(rstan)
require(rstan)
require(rstan)
require(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = 1)
# Compile the model
hnm_mod <- stan_model(file = "HierNorm.stan")
nCores <- parallel::detectCores()
nCores
nCores <- parallel::detectCores(logical = FALSE)
nCores
options(mc.cores = nCores)
stan_time <- system.time(
hnm_fit <- sampling(hnm_mod, data = hnm_data, iter = nsamples,
control = list(adapt_delta = 0.99, max_treedepth = 15)))
require(doParallel)
nCores <- parallel::detectCores(logical = FALSE)
# create the parallel cluster
cl <- makeCluster(spec = nCores, setup_strategy = "sequential")
# create the parallel cluster
cl <- makeCluster(spec = nCores, setup_strategy = "sequential")
registerDoParallel(cl) # inform doParallel
clusterSetRNGStream(cl)
options(mc.cores = nCores)
stan_time <- system.time(
hnm_fit <- sampling(hnm_mod, data = hnm_data, iter = nsamples,
control = list(adapt_delta = 0.99, max_treedepth = 15)))
theta <- c("lambda","tau_sq","sigma_sq")
theta.names <- c(paste0('lambda'),  paste0('tau'^2),
paste0('sigma'^2))
theta <- c("lambda","tau_sq","sigma_sq")
theta.names <- c(paste0('lambda'),  paste0('tau','^2'),
paste0('sigma','^2'))
theta.names <- parse(text = theta.names)
stan_trace(hnm_fit, pars = theta) # trace plot
stan_dens(hnm_fit, pars = theta, separate_chains = TRUE) #kernel density estimates
stan_trace(hnm_fit, pars = theta, xnames= theta.names) # trace plot
theta.names
theta <- c("lambda","tau_sq","sigma_sq")
theta.names <- c(paste0('lambda'),  paste0('tau','^2'), paste0('sigma','^2'))
theta.names <- parse(text = theta.names)
stan_trace(hnm_fit, pars = theta, xnames= theta.names) # trace plot
trace <- stan_trace(hnm_fit, pars = theta) # trace plot
trace +
labs(title = theta.names)
trace +
labs(subtitle = theta.names)
theta <- c("lambda","tau_sq","sigma_sq")
theta.names <- c(paste0('lambda'),  paste0('tau','^2'), paste0('sigma','^2'))
theta.names <- parse(text = theta.names)
trace <- stan_trace(hnm_fit, pars = theta) # trace plot
trace +
labs(subtitle = theta.names[2])
for(ii in 1:3){
trace <- stan_trace(hnm_fit, pars = theta[ii])
trace +
labs(title = theta.names[ii],)
}
theta[ii]
for(ii in 1:3){
trace <- stan_trace(hnm_fit, pars = c(theta[ii]) )
trace +
labs(title = theta.names[ii],)
}
for(ii in 1:3){
trace <- stan_trace(hnm_fit, pars = c(theta[ii]) )
trace +
labs(title = theta.names[ii])
}
par(mfrow = c(1,3))
for(ii in 1:3){
trace <- stan_trace(hnm_fit, pars = c(theta[ii]) )
trace +
labs(title = theta.names[ii])
}
par(mfrow = c(1,3))
for(ii in 1:3){
trace <- stan_trace(hnm_fit, pars = c(theta[ii]) )
trace +
labs(title = theta.names[ii])
}
trace <- stan_trace(hnm_fit, pars = theta) # trace plot
trace +
theme(plot.title = theta.names)
trace <- stan_trace(hnm_fit, pars = theta) # trace plot
trace +
theme(plot.title = element_text(theta.names))
trace <- stan_trace(hnm_fit, pars = theta) # trace plot
trace +
theme(plot.title = element_text("$\\lambda$", "\\tau^2", "\\sigma^2"))
trace <- stan_trace(hnm_fit, pars = c('lambda') ) # trace plot
trace +
lab(title = theta.names[1])
trace <- stan_trace(hnm_fit, pars = c('lambda') ) # trace plot
trace +
labs(title = theta.names[1])

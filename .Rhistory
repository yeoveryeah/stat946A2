se = c(ols = LS$se, white = white$se, efrron = efrron$se,
WLS = WLS$se, FGLS.f = FGLS.f$se)
c(point = point, se = se)
}
})
stopCluster(cl)
View(S)
system.time({
# create the parallel cluster
cl <- makeCluster(spec = nCores, setup_strategy = "sequential")
registerDoParallel(cl) # inform doParallel
clusterSetRNGStream(cl)
})
system.time({
# create the parallel cluster
cl <- makeCluster(spec = nCores, setup_strategy = "sequential")
registerDoParallel(cl) # inform doParallel
clusterSetRNGStream(cl)
})
cl
# True parameter:
t.beta <- c(1,1)
t.cc <- 0.7
t.theta <- 0.8
t.rho <- 0.5
n.sim <- 2e5
T.obs <- 60
system.time({
S <- foreach(ii = 1:10, .combine = "rbind") %dopar% {
# Generate Data:
sigma2.u <- rgamma(T.obs, shape = t.cc/t.theta,
rate = 1/t.theta)# sigma2.u
ut <- rnorm(T.obs, sd = sqrt(sigma2.u)) # u_t
et <- rnorm(T.obs, sd = sqrt(1-t.cc)) # epsilon_t
vt <- ut+et # v_t
# `T X 2` matrix
X <- cbind(1, sigma2.u/(t.rho*sqrt(t.cc*t.theta)))
y <- X %*% t.beta + vt # yt
# Estimate beta:
LS <- LS.or(y, X)
white <- white.or(y, X)
efrron <- boot.or(y, X)
WLS <- WLS.or(y, X, sigma2.u)
FGLS.f <- FGLS.full(y,X, sigma2.u)
#TBD --- FGLS.p <- FGLS.prop(y,X,nt)
# Output: Regression Slope
point = c(ols = LS$point, white = white$point, efrron = efrron$point,
WLS = WLS$point, FGLS.f = FGLS.f$point)
se = c(ols = LS$se, white = white$se, efrron = efrron$se,
WLS = WLS$se, FGLS.f = FGLS.f$se)
c(point = point, se = se)
}
})
stopCluster(cl)
View(S)
require(foreach)
require(doParallel)
nCores <- detectCores(logical = FALSE)
# create the parallel cluster
cl <- makeCluster(spec = nCores, setup_strategy = "sequential")
registerDoParallel(cl) # inform doParallel
clusterSetRNGStream(cl)
nt <- sample(T.obs, T.obs, replace = TRUE)
X.prop <- foreach(ii = 1:T.obs, .combine = rbind) %dopar%
c(1, mean(rnorm(nt[ii], mean = sigma2.u[ii])))
y.prop <- X.prop %*% t.beta + vt # yt
stopCluster(cl)
# FGLS - partially known sigma_u
#   unknown sigma_eps
FGLS.prop <- function(y, X, nt){
vt2 <- resid(lm(y ~ X -1))^2 # Step 1
nt.inv <- 1/nt
sigma2.eps <- coef(lm(vt2 ~ nt.inv))[1]
if (sigma2.eps < 0) {
sigma2.eps <- 0
sigma2.u <- coef(lm(vt2 ~ nt.inv -1))
}else{
sigma2.u <- coef(lm(vt2 ~ nt.inv))[2]*nt
}
# Stage II - WLS:
WLS.or(y, X, sigma2.eps+sigma2.u)
}
FGLS.prop(y.prop, X.prop, nt)
# Install from CRAN
install.packages('rmarkdown')
install.packages('tinytex')
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
require(ggplot2)
require(foreach)
require(doParallel)
nCores <- detectCores(logical = FALSE)
# create the parallel cluster
cl <- makeCluster(spec = nCores, setup_strategy = "sequential")
registerDoParallel(cl) # inform doParallel
clusterSetRNGStream(cl)
set.seed(42)
nt <- sample(T.obs, T.obs, replace = TRUE)
X.prop <- foreach(ii = 1:T.obs, .combine = rbind) %dopar%
c(1, mean(rnorm(nt[ii], mean = sigma2.u[ii])))
y.prop <- X.prop %*% t.beta + vt # yt
stopCluster(cl)
# FGLS - partially known sigma_u
#   unknown sigma_eps
FGLS.prop <- function(y, X, nt){
vt2 <- resid(lm(y ~ X -1))^2 # Step 1
nt.inv <- 1/nt
sigma2.eps <- coef(lm(vt2 ~ nt.inv))[1]
if (sigma2.eps < 0) {
sigma2.eps <- 0
sigma2.u <- coef(lm(vt2 ~ nt.inv -1))
}else{
sigma2.u <- coef(lm(vt2 ~ nt.inv))[2]*nt
}
# Stage II - WLS:
WLS.or(y, X, sigma2.eps+sigma2.u)
}
FGLS.prop(y.prop, X.prop, nt)
update.packages(ask = FALSE, checkBuilt = TRUE)
install.packages("Rcpp")
install.packages('backports')
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
library(knitr)
install.packages("kableExtra")
install.packages("shiny")
install.packages("bookdown")
install.packages("forecast")
install.packages("numbers")
knitr::opts_chunk$set(eval = FALSE, message = FALSE, warning = FALSE)
#saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time), file = "hnm_post.rds")
require(rstan)
hnm_mcmc <- readRDS('hnm_post.rds')
hnm_fit <- hnm_mcmc$hnm_fit # MCMC samples
stan_time <- hnm_mcmc$stan_time
hnm_post <- extract(hnm_fit)
rm(hnm_mcmc)
theta <- c("lambda","tau_sq","sigma_sq")
trace <- stan_trace(hnm_fit, pars = theta) # trace plot
dens <- stan_dens(hnm_fit, pars = theta, separate_chains = TRUE) #kernel density estimates
theta <- c("lambda","tau_sq","sigma_sq")
trace <- stan_trace(hnm_fit, pars = theta, ncol = 1) # trace plot
dens <- stan_dens(hnm_fit, pars = theta, separate_chains = TRUE, ncol = 1) #kernel density estimates
require(ggplot2)
gridExtra::grid.arrange(trace, dens)
gridExtra::grid.arrange(trace, dens, ncol = 2)
gridExtra::grid.arrange(dens,trace, ncol = 2) # arrange the plots
library(rstan)
knitr::opts_chunk$set(eval = FALSE, message = FALSE, warning = FALSE)
stan_hist(hnm_fit, pars = theta)
#saveRDS(list(hnm_fit= hnm_fit, stan_time = stan_time), file = "hnm_post.rds")
require(rstan)
hnm_mcmc <- readRDS('hnm_post.rds')
hnm_fit <- hnm_mcmc$hnm_fit # MCMC samples
stan_time <- hnm_mcmc$stan_time
hnm_post <- extract(hnm_fit)
rm(hnm_mcmc)
stan_hist(hnm_fit, pars = theta)
theta <- c("lambda","tau_sq","sigma_sq")
stan_hist(hnm_fit, pars = theta)
stan_fit(hnm_fit, pars = theta, point_est = "mean")
stan_plot(hnm_fit, pars = theta, point_est = "mean")
hist <- stan_hist(hnm_fit, pars = theta)
quietgg(hist)
quietgg(hist)
set.seed(42) # for reproducibility
N <- 20 # number of clusters
true_lam <- 3 # true population mean
true_tau2 <- 1.5 # true cross -cluster variance
true_sig2 <- 1.2 # true inter-cluster variance
true_mu <-true_lam + sqrt(true_tau2)*rnorm(N) # true cluster means
y <- true_mu + sqrt(true_sig2)*rnorm(N) # observed data input for models
hist <- stan_hist(hnm_fit, pars = theta)
hist + geom_vline(xintercept = c(true_lam, true_tau2, true_sig2))
Pars <- replicate(n = 1, expr = {
list(lambda_tilda = 1,
tau_sq = 5, sigma_sq = 4)
}, simplify = FALSE)
# log-posterior calculation in R:
lpR <- sapply(1:nsim, function(ii) {
lambda_tilda <- Pars[[ii]]$lambda_tilda
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda_tilda = lambda_tilda,
tau_sq = tau_sq, sigma_sq = sigma_sq, y = hnm_data$y)
})
# log-posterior calculation in R:
lpR <- sapply(1:1, function(ii) {
lambda_tilda <- Pars[[ii]]$lambda_tilda
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda_tilda = lambda_tilda,
tau_sq = tau_sq, sigma_sq = sigma_sq, y = hnm_data$y)
})
#' Log-Posterior Function
#'
#' @description  `logpost` returns the log-posterior of the hierarchical model given the parameter values and observations
#'
#' @param lambda_tilda A real number, the hyperparameter
#' @param tau_sq A positive number, the hyperparameter
#' @param sigma_sq A positive number
#' @param y A vector of reals
#' @return The log-posterior values
#' @details The hyper-prior are given by tau_sq ~ InverseGamma(1,1) and lambda_tilda ~ N(0,1) such that lambda ~ N(0,100).
#' The prior are given by sigma_sq InverseGamma(1,1);
#' The likelihood are given by the Normal(lambda, sqrt(sigma_sq + tau_sq))
#' @import invgamma
#' @export
logpost <- function(lambda_tilda, tau_sq, sigma_sq, y) {
require(invgamma)
# Hyper-prior:
lp <- dnorm(lambda_tilda, log = TRUE)
lp <- lp + dinvgamma(tau_sq, shape = 1, scale = 1, log = TRUE)
# Prior:
lp <- lp + dinvgamma(sigma_sq, shape = 1, scale = 1, log = TRUE)
# likelihood:
lambda <- 10*lambda_tilda
y_sd <- sqrt(sigma_sq+tau_sq)
lp <- lp + sum(dnorm(y, mean = lambda, sd = y_sd, log = TRUE))
# output:
lp
}
# log-posterior calculation in R:
lpR <- sapply(1:1, function(ii) {
lambda_tilda <- Pars[[ii]]$lambda_tilda
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda_tilda = lambda_tilda,
tau_sq = tau_sq, sigma_sq = sigma_sq, y = hnm_data$y)
})
set.seed(42) # for reproducibility
N <- 20 # number of clusters
true_lam <- 3 # true population mean
true_tau2 <- 1.5 # true cross -cluster variance
true_sig2 <- 1.2 # true inter-cluster variance
true_mu <-true_lam + sqrt(true_tau2)*rnorm(N) # true cluster means
y <- true_mu + sqrt(true_sig2)*rnorm(N) # observed data input for models
#  1. format data:
#   list with elements named exactly as "data" block in Stan
hnm_data <- list(N = N, y = y)
# log-posterior calculation in R:
lpR <- sapply(1:1, function(ii) {
lambda_tilda <- Pars[[ii]]$lambda_tilda
tau_sq <- Pars[[ii]]$tau_sq
sigma_sq <- Pars[[ii]]$sigma_sq
logpost(lambda_tilda = lambda_tilda,
tau_sq = tau_sq, sigma_sq = sigma_sq, y = hnm_data$y)
})
lpR
library(reticulate)
require(reticulate)
use_python('/Library/Frameworks/Python.framework/Versions/3.8/bin/python3')
py_config()
require(reticulate)
use_python('/Library/Frameworks/Python.framework/Versions/3.8/bin/python3', required = TRUE)
library(bayesplot)
setwd("~/Desktop/MMath/Term3_20S/STAT946/A2/stat946A2")
require(rstan)
rstan_options(auto_write = TRUE)
# Compile the model
hnm_mod <- stan_model(file = "HierNorm.stan")
require(rstan)
rstan_options(auto_write = TRUE)
# Compile the model
hnm_mod <- stan_model(file = "HierNorm.stan")
#  1. format data:
#   list with elements named exactly as "data" block in Stan
hnm_data <- list(N = N, y = y)
require(rstan)
rstan_options(auto_write = TRUE)
# Compile the model
hnm_mod <- stan_model(file = "HierNorm.stan")
set.seed(42) # for reproducibility
N <- 20 # number of clusters
true_lam <- 3 # true population mean
true_tau2 <- 1.5 # true cross -cluster variance
true_sig2 <- 1.2 # true inter-cluster variance
true_mu <-true_lam + sqrt(true_tau2)*rnorm(N) # true cluster means
y <- true_mu + sqrt(true_sig2)*rnorm(N) # observed data input for models
require(rstan)
rstan_options(auto_write = TRUE)
# Compile the model
hnm_mod <- stan_model(file = "HierNorm.stan")
#  1. format data:
#   list with elements named exactly as in the `data block in Stan
hnm_data <- list(N = N, y = y)
#  2. associate data with model:
#   MCMC sample for one iteration.
hnm_fit_init <- sampling(hnm_mod, data = hnm_data, iter = 1,
verbose = FALSE, chains = 1)
nsamples <- 1e4 # number of total iterations
start_time <- Sys.time()# To measure the running time:
# Sampling:
hnm_fit <- sampling(hnm_mod, data = hnm_data, iter = nsamples,
control = list(adapt_delta = 0.99))
end_time <- Sys.time()
stan_time <- end_time - start_time
stan_time
# extract MCMC samples
hnm_post <- extract(hnm_fit)
stan_time
lambda_seq = seq(range(lambda_post), len = 200)
lambda_post = hnm_post$lambda
sig2_post = hnm_post$sigma_sq
tau2_post = hnm_post$tau_sq
lambda_seq = seq(range(lambda_post), len = 200)
t <- mapply(logpost, lambda_seq, tau2_seq, sig2_seq, y=y)
logpost <- function(lambda_tilda, tau_sq, sigma_sq, y) {
require(invgamma)
# Hyper-prior:
lp <- dnorm(lambda_tilda, log = TRUE)
lp <- lp + dinvgamma(tau_sq, shape = 1, scale = 1, log = TRUE)
# Prior:
lp <- lp + dinvgamma(sigma_sq, shape = 1, scale = 1, log = TRUE)
# likelihood:
lambda <- 10*lambda_tilda
y_sd <- sqrt(sigma_sq+tau_sq)
lp <- lp + sum(dnorm(y, mean = lambda, sd = y_sd, log = TRUE))
# output:
lp
}
t <- mapply(logpost, lambda_seq, tau2_seq, sig2_seq, y=y)
# Calculate the true posterior:
lambda_post = hnm_post$lambda
sig2_post = hnm_post$sigma_sq
tau2_post = hnm_post$tau_sq
lambda_seq = seq(min(lambda_post), max(lambda_post), len = 200)
sig2_seq = seq(min(sig2_post), max(sig2_post), len = 200)
tau2_seq = seq(min(tau2_post), max(sig2_post), len = 200)
t <- mapply(logpost, lambda_seq, tau2_seq, sig2_seq, y=y)
View(t)
length(t)
logpost(lambda_seq[1], tau2_seq[1], sig2_seq[1], y=y)
t <- mapply(logpost(y=y), lambda_seq, tau2_seq, sig2_seq)
list(y=y)
rep(list(y=y), 2)
t <- mapply(logpost, lambda_seq, tau2_seq, sig2_seq, rep(list(y=y), 200))
t[1]
theta_pdf <- matrix(mapply(logpost, lambda_seq, tau2_seq, sig2_seq, rep(list(y=y), 200)), 200, 200)
View(theta_pdf)
# Calculate the true posterior:
lambda_post = hnm_post$lambda
sig2_post = hnm_post$sigma_sq
tau2_post = hnm_post$tau_sq
par(mfrow =c(1,3))
# population mean:
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Posterior of Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_lam, lty = 1, lwd = 2, col = 'red') # True population mean
abline(v = mean(lambda_post), lty = 2, lwd = 2, col = 'orange') # Posterior mean
# Population variance
hist(tau2_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Posterior of Population Variance', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_tau2, lty = 1, lwd = 2, col = 'red') # True population variance
abline(v = mean(tau2_post), lty = 2, lwd = 2, col = 'orange') # Posterior variance
# Residual Variance
hist(sig2_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Posterior of Residual Variance', xlab = expression(lambda), ylim=c(0,0.8))
abline(v = true_sig2, lty = 1, lwd = 2, col = 'red') # True residual variance
abline(v = mean(sig2_post), lty = 2, lwd = 2, col = 'orange') # Posterior residual vairance
legend("right", col = c("red", "orange"), c("True Parameter","Mean of Posterior"),
lty = c(1,2), cex = 1, bty='n')# add legends
summary(hnm_fit, pars= theta)
theta <- c("lambda","tau_sq","sigma_sq")
trace <- stan_trace(hnm_fit, pars = theta, ncol = 1) # trace plot
dens <- stan_dens(hnm_fit, pars = theta, separate_chains = TRUE, ncol = 1) #kernel density estimates
gridExtra::grid.arrange(dens,trace, ncol = 2) # arrange the plots
summary(hnm_fit, pars= theta)
summary(hnm_fit, pars= theta)$summary
summary(hnm_fit, pars= theta)$summary['mean', 'sd', 'n_eff', 'Rhat']
summary(hnm_fit, pars= theta)$summary
summary(hnm_fit, pars= theta)$summary[,c(1,3,9,10)]
knitr::opts_chunk$set(echo = TRUE)
theta_post = extract(hnm_fit, pars = theta)
View(theta_post)
# `stan_hist` will do the same work for the following:
# plot the histogram of the MCMC samples of population mean
lambda_post = hnm_post$lambda
# `stan_hist` will do the same work for the following:
# plot the histogram of the MCMC samples of population mean
lambda_post = hnm_post$lambda
theta_seq = lapply(theta_post, function(x) seq(min(x), max(x), seq =200))
theta_seq
range(lambda_post)
theta_seq = lapply(theta_post, function(x) seq(min(x), max(x), len = 200))
theta_seq$lambda
t <- matrix(mapply(logpost, theta_post$lambda, theta_post$tau_sq, theta_post$sigma_sq,
)
))
t <- matrix(mapply(logpost, theta_post$lambda, theta_post$tau_sq, theta_post$sigma_sq,
rep(list(y=y), 200)), 200,200)
rowSums(t)
lam_pdf <- exp(t-max(t))
lam_pdf <- rowSums(lam_pdf)
xpdf <- rowSums(lam_pdf)
lam_pdf <- exp(t-max(t))
xpdf <- rowSums(lam_pdf)
xpdf <- xpdf/sum(xpdf)/(xseq[2]-xseq[1])
lam_pdf <- exp(t-max(t))
xpdf <- rowSums(lam_pdf)
xpdf <- xpdf/sum(xpdf)/(lambda_seq[2]-lambda_seq[1])
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Posterior of Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lines(lambda_seq, lambda_seq)
hist(lambda_post, breaks = 80, probability = TRUE, col = 'white',
main = 'Posterior of Population Mean', xlab = expression(lambda), ylim=c(0,0.8))
lines(lambda_seq, lambda_seq)
require(bayesplot)
color_scheme_set(scheme = "mix-teal-blue") #(Optional) set a color scheme for the plots
mcmc_areas(hnm_fit, pars = theta) # Plot marginal posterior distributions
require(bayesplot)
color_scheme_set(scheme = "mix-teal-blue") #(Optional) set a color scheme for the plots
mcmc_areas(hnm_post, pars = theta) # Plot marginal posterior distributions
require(bayesplot)
color_scheme_set(scheme = "mix-teal-blue") #(Optional) set a color scheme for the plots
mcmc_areas(theta_post, pars = theta) # Plot marginal posterior distributions
require(bayesplot)
color_scheme_set(scheme = "mix-teal-blue") #(Optional) set a color scheme for the plots
mcmc_areas(theta_post) # Plot marginal posterior distributions
hnm_post <- as.array(hnm_post)
mcmc_areas(theta_post) # Plot marginal posterior distributions
dim(hnm_post)
View(hnm_post)
hnm_post <- as.array(hnm_post, dim = c(nsamples/2, 4, 6))
View(hnm_post)
mcmc_areas(theta_post) # Plot marginal posterior distributions
mcmc_areas(hnm_post) # Plot marginal posterior distributions
theta_post <- nuts_params(hnm_fit, pars = theta)
theta_post <- nuts_params(hnm_fit)
View(theta_post)
theta_post <- extract(hnm_fit, pars = theta)
dim(theta_post)
View(theta_post)
dim(as.array(theta_post))
theta_post <- as.matrix(hnm_fit)
dim(theta_post)
mcmc_areas(theta_post, pars = theta) # Plot marginal posterior distributions
mcmc_areas(posterior,
pars = c("cyl", "drat", "am", "wt"), point_est = 'mean',
prob = 0.8) + plot_title
mcmc_areas(posterior,
pars = c("cyl", "drat", "am", "wt"), point_est = 'mean',
prob = 0.95) + ggtitle("Posterior distributions",
"with means and 95% intervals")
mcmc_areas(theta_post, pars = theta, point_est = 'mean',
prob = 0.95) + ggtitle("Posterior distributions",
"with means and 95% intervals")
mcmc_areas(theta_post, pars = theta, point_est = 'mean',
prob = 0.95) + ggtitle("Posterior distributions",
"with means and 95% intervals") + xlim(0,20)
mcmc_areas(theta_post, pars = theta, point_est = 'mean',
prob = 0.95) + ggtitle("Posterior distributions",
"with means and 95% intervals")
bayesplot_grid(xlim = c(0,20))
bayesplot_grid(plots =mcmc_areas(theta_post, pars = theta, point_est = 'mean',
prob = 0.95),
xlim = c(0,20))
bayesplot_grid(plots =list(mcmc_areas(theta_post, pars = theta, point_est = 'mean',
prob = 0.95)),
xlim = c(0,20))
mcmc_areas(theta_post, pars = theta, point_est = 'mean',
prob = 0.95) + ggtitle("Posterior distributions",
"with means and 95% intervals")
bayesplot_grid(plots =lappy(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)),
xlim = c(0,20))
bayesplot_grid(plots =lapply(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)),
xlim = c(0,20))
bayesplot_grid(plots =lapply(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)), grid_args = list(nrow = 1)
xlim = c(0,20))
bayesplot_grid(plots =lapply(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)), grid_args = list(nrow = 1),
xlim = c(0,20))
bayesplot_grid(plots =lapply(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)), grid_args = list(nrow = 1))
bayesplot_grid(plots =lapply(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)), grid_args = list(nrow = 1), titles = "Posterior distributions with means and 95% intervals")
bayesplot_grid(plots =lapply(theta, function(x) mcmc_areas(theta_post, pars = x, point_est = 'mean',
prob = 0.95)), grid_args = list(nrow = 1))+ ggtitle("Posterior distributions",
"with means and 95% intervals")
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.95)),
grid_args = list(nrow = 1)) +
ggtitle("Posterior distributions", "with means and 95% intervals")
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.95)),
grid_args = list(nrow = 1))
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.90)),
subtitles = expression('lambda', 'tau^2', paste0('sigma',^2)),
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.90)),
subtitles = expression('lambda', 'tau^2', paste0('sigma','^2')),
grid_args = list(nrow = 1))
expression(lambda, paste0('tau', '^2'), paste0('sigma','^2'))
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.90)),
subtitles = expression(lambda, paste0('tau', '^2'), paste0('sigma','^2')),
grid_args = list(nrow = 1))
is.character(expression(lambda, paste0('tau', '^2'), paste0('sigma','^2')))
is.character(as.character(expression(lambda, paste0('tau', '^2'), paste0('sigma','^2'))))
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.90)),
subtitles = as.character(expression(lambda, paste0('tau', '^2'), paste0('sigma','^2'))),
grid_args = list(nrow = 1))
class(expression(lambda, paste0('tau', '^2'), paste0('sigma','^2')))
bayesplot_grid(plots =lapply(theta, function(x)
mcmc_areas(theta_post, pars = x, point_est = 'mean', prob = 0.90)),
subtitles = theta,
grid_args = list(nrow = 1))
